{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8196e9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5be7102",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_string=\"文本最重要的来源无疑是网络。我们要把网络中的文本获取形成一个文本数据库。利用一个爬虫抓取到网络中的信息。爬取的策略有广度爬取和深度爬取。根据用户的需求，爬虫可以有主题爬虫和通用爬虫之分。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ca884f0-a945-4d0a-bad6-66eb8527b861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'文本最重要的来源无疑是网络。我们要把网络中的文本获取形成一个文本数据库。利用一个爬虫抓取到网络中的信息。爬取的策略有广度爬取和深度爬取。根据用户的需求，爬虫可以有主题爬虫和通用爬虫之分。'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5462ec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_string=text_string.split(\"。\")# 以句号为分隔符通过split切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1d10b77-7d17-4a9a-b73c-950f24454433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['文本最重要的来源无疑是网络',\n",
       " '我们要把网络中的文本获取形成一个文本数据库',\n",
       " '利用一个爬虫抓取到网络中的信息',\n",
       " '爬取的策略有广度爬取和深度爬取',\n",
       " '根据用户的需求，爬虫可以有主题爬虫和通用爬虫之分',\n",
       " '']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da7303f0-1fb0-4f6d-a486-0268d741543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex=\"爬虫\" # 获取包含\"爬虫\"这个关键词的句子\n",
    "regex=\"爬.\" # 获取包含\"爬\"+任意一个字的句子\n",
    "regex=\"^文本\" # 获取以\"文本\"两个字起始的句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d560212b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文本最重要的来源无疑是网络\n"
     ]
    }
   ],
   "source": [
    "for line in p_string:\n",
    "    if re.search(regex,line) is not None: # 如果当前行匹配regex的结果不是None\n",
    "        print(line) # 就打印这行信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88b0d612",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_string=[\"[重要的]今年第七号台风23日登录广东东部沿海地区\",\"上海发布车库销售监管通知：违规者暂停网签资格\",\"[紧要的]中国对印连发强硬信息，印度急切需要结束对峙\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58ccb7be-fc0c-4027-b9a7-04c7361ca465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[重要的]今年第七号台风23日登录广东东部沿海地区',\n",
       " '上海发布车库销售监管通知：违规者暂停网签资格',\n",
       " '[紧要的]中国对印连发强硬信息，印度急切需要结束对峙']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "239d7541",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex=\"^\\[[重紧]..\\]\" # 提取以\"重要的\"或者\"紧要的\"为起始的新闻标题，反斜杠\\为转义符，因为[]是特殊符号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a504a941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[重要的]今年第七号台风23日登录广东东部沿海地区\n",
      "not match\n",
      "[紧要的]中国对印连发强硬信息，印度急切需要结束对峙\n"
     ]
    }
   ],
   "source": [
    "for line in text_string:\n",
    "    if re.search(regex,line) is not None: # 如果当前行匹配regex的结果不是None\n",
    "        print(line) # 就打印这行信息\n",
    "    else:\n",
    "        print(\"not match\") #否则打印\"not match\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c93b5b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "strings=[\"war of 1812\",\"There are 5280 feet to a mile\",\"Happy New Year 2016!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e9a7375-a98c-4bca-8148-81b9d71e3dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['war of 1812', 'There are 5280 feet to a mile', 'Happy New Year 2016!']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2b17735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['war of 1812', 'Happy New Year 2016!']\n"
     ]
    }
   ],
   "source": [
    "year_strings=[]\n",
    "for string in strings:\n",
    "    if re.search(\"[1-2][0-9][0-9][0-9]\",string):# 字符串有英文有数字，匹配其中的数字部分，并且在1000~2999之间\n",
    "        year_strings.append(string)\n",
    "print(year_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c94e4d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_string=\"2016 was a good year, but 2017 will be better!\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74b2bdeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2016', '2017']\n"
     ]
    }
   ],
   "source": [
    "years=re.findall(\"[2][0-9][0-9][0-9]\",year_string)#抽取所有年份\n",
    "print(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2d6ae30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic=[\"研究\",\"研究生\",\"生命\",\"命\",\"的\",\"起源\"]\n",
    "text=\"研究生命的起源\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cae2b2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def cut(dic,text):\n",
    "    result=[]\n",
    "    index=0\n",
    "    text_length=len(text)\n",
    "    length=[]\n",
    "    for word in dic:\n",
    "        length.append(len(word))\n",
    "    m=max(length)\n",
    "    while text_length>index:\n",
    "        for size in np.arange(m+index,index,-1):\n",
    "            piece=text[index:size]\n",
    "            if piece in dic:\n",
    "                result.append(piece)\n",
    "                index=size\n",
    "                break        \n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23a0e59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['研究生', '命', '的', '起源']\n"
     ]
    }
   ],
   "source": [
    "cut(dic,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5f08013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba as jb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8c68bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"中文分词是文本处理不可或缺的一步！\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbd8ff0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\WINDOW~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.806 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['中文', '分词', '是', '文本', '文本处理', '本处', '处理', '不可', '不可或缺', '或缺', '的', '一步', '！']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cut_all = True表示全模式，把句子中所有可以成词的组合都找出来\n",
    "jb.lcut(sent, cut_all = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5652020f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['中文', '分词', '是', '文本处理', '不可或缺', '的', '一步', '！']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cut_all = False表示精确模式，对句子进行最准确的分割\n",
    "jb.lcut(sent, cut_all = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e3d10c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['中文', '分词', '是', '文本', '本处', '处理', '文本处理', '不可', '或缺', '不可或缺', '的', '一步', '！']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 搜索引擎模式，在精确模式基础上，对长词进一步分割\n",
    "jb.lcut_for_search(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecd1dd62-fbeb-4cb5-b9ef-00321d29a4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['南京大学商学院', '位于', '费彝民', '楼', '西侧']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自定义词典\n",
    "# 词典格式：每一行分三部分，词语，词频（可省略），词性（可省略），用空格隔开，顺序不可颠倒\n",
    "# 自定义词典存放为txt文件，使用的时候导入\n",
    "sent = \"南京大学商学院位于费彝民楼西侧\"\n",
    "jb.lcut(sent, cut_all = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd7cec7e-4f16-4d0d-b77d-523fdced39ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['南京大学商学院', '位于', '费彝民楼', '西侧']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jb.load_userdict(r\"E:\\Teaching\\数据挖掘与最优化\\Code\\user_words.txt\")\n",
    "jb.lcut(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4844f37d-36f4-4c7c-a444-d7a4caa2b22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[pair('南京大学商学院', 'x'), pair('位于', 'v'), pair('费彝民楼', 'x'), pair('西侧', 'f')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jieba在分词基础上还提供词性标注(Part-of-Speech tagging, POS)功能\n",
    "# jieba词性列表：https://gist.github.com/hscspring/c985355e0814f01437eaf8fd55fd7998\n",
    "import jieba.posseg as pseg\n",
    "pseg.lcut(sent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
