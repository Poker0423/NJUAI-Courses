{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建虚拟环境\n",
    "- python的虚拟环境是用来隔离不同版本的python环境，避免不同版本的python之间产生冲突。\n",
    "- 隔绝依赖：不同项目可能需要不同的python环境和系统环境，通过虚拟环境可以为每个项目创建独立的环境，避免版本冲突。\n",
    "* conda create -n llmdeepseek python=3.10 ## 创建虚拟环境\n",
    "* conda activate llmdeepseek    ## 激活虚拟环境\n",
    "* conda deactivate ## 退出虚拟环境\n",
    "* conda env remove -n llmdeepseek ## 删除虚拟环境\n",
    "* conda env list ## 查看所有虚拟环境\n",
    "* pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 安装Ai代码助手\n",
    "- 常用的ai代码助手有GitHub Copilot、通义灵码、Cursor等\n",
    "- TONGYI Lingma 通义灵码是基于llm的代码智能助手，支持以下功能：\n",
    "  * 行/函数级代码实时续写\n",
    "  * 注释代码\n",
    "  * 在线询问\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 调用deepseek api，进行文本分析\n",
    "* https://www.deepseek.com/\n",
    "* 访问网站，注册账号，创建key\n",
    "* 大规模批量处理\n",
    "* 结构化的保存数据\n",
    "* 调整模型的回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai\n",
    "from openai import OpenAI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please install OpenAI SDK first: `pip install openai`\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"sk-c05e04a3f39a492e9e314c4ffe12507d\", base_url=\"https://api.deepseek.com\") \n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-reasoner\",  #deepseek-reasoner，deepseek-chat\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"deepseek和chatgpt谁更厉害？\"}, \n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content) #输出结果 \n",
    "print(response.choices[0].message.reasoning_content)   #推理结果 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 场景1  批量进行文本分析 根据文本，判断情感倾向\n",
    "\n",
    "sentences = [\n",
    "    \"这部电影太棒了，我非常喜欢！\",\n",
    "    \"天气太糟糕了，真让人沮丧。\",\n",
    "    \"这个产品还不错，但可以更好。\",\n",
    "    \"我对这次选举结果感到不满。\",\n",
    "    \"今天过得很开心，希望明天也一样好！\"\n",
    "]\n",
    "\n",
    "def ds_sentiment_analysis(sentence):\n",
    "    prompt=f\"\"\"请严格遵循以下规则：\n",
    "                    1. 分析以下句子的情感分数（范围：-1到1）：\\n{sentence}\"\n",
    "                    2. 输出格式：数字，范围：-1到1，越接近1代表越积极，越接近-1代表越消极。0代表中立\n",
    "                    3. 示例：0.5\n",
    "                    4. 不包含其他任何文字\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",  #deepseek-reasoner，deepseek-chat\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=1024, #最终回答的最大长度（不含思维链输出），默认为 4K，最大为 8K\n",
    "        temperature=0.8, #采样温度，介于 0 和 2 之间。更高的值，如 0.8，会使输出更随机，而更低的值，如 0.2，会使其更加集中和确定。\n",
    "    )\n",
    "    print(sentence)\n",
    "    print(response.choices[0].message.content) #输出结果 \n",
    "    return response\n",
    "\n",
    "for sentence in sentences:\n",
    "    sentiment=ds_sentiment_analysis(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 场景2  批量查找信息 根据大学名字，定位国家和城市\n",
    "\n",
    "universities = [\n",
    "    \"University of Cambridge\",\n",
    "    \"University of Tokyo\",\n",
    "    \"ETH Zurich\",\n",
    "    \"National University of Singapore\"\n",
    "]\n",
    "\n",
    "def ds_university_name(university):\n",
    "    prompt=f\"\"\"请严格遵循以下规则：\n",
    "                    1. 查询{university}的物理地址\n",
    "                    2. 输出格式：<城市>, <国家全称>\n",
    "                    3. 示例：Cambridge, United Kingdom\n",
    "                    4. 不包含其他任何文字\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",  #deepseek-reasoner，deepseek-chat\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant\"},{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=1024, #最终回答的最大长度（不含思维链输出），默认为 4K，最大为 8K\n",
    "        temperature=0.1, #采样温度，介于 0 和 2 之间。更高的值，如 0.8，会使输出更随机，而更低的值，如 0.2，会使其更加集中和确定。\n",
    "    )\n",
    "    #print(response)\n",
    "    print(response.choices[0].message.content) #输出结果 \n",
    "    return response\n",
    "\n",
    "for university in universities:\n",
    "    country=ds_university_name(university)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 场景三，翻译\n",
    "def ds_text_translate(text):\n",
    "    prompt=f\"请将以下中文翻译成英文：\\n{text}\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",  #deepseek-reasoner，deepseek-chat\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=1024, #最终回答的最大长度（不含思维链输出），默认为 4K，最大为 8K\n",
    "        temperature=0.8, #采样温度，介于 0 和 2 之间。更高的值，如 0.8，会使输出更随机，而更低的值，如 0.2，会使其更加集中和确定。\n",
    "    )\n",
    "    print(text)\n",
    "    print(response.choices[0].message.content) #输出结果 \n",
    "    return response\n",
    "\n",
    "with open('example.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "sentiment=ds_text_translate(text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
